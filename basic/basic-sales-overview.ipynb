{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d137f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from scipy.stats import zscore\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('ggplot') \n",
    "pd.options.display.float_format = '{:.2f}'.format \n",
    "pd.options.display.max_columns=None\n",
    "pd.options.display.max_rows=None\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16a56d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'customer_shopping_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustomer_shopping_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'customer_shopping_data.csv'"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "\n",
    "df = pd.read_csv('customer_shopping_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dda466",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The data has {0} rows and {1} features.\".format(df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79535ddb",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3aa2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invoice_date'] = pd.to_datetime(df['invoice_date'])\n",
    "df['invoice_year'] = df['invoice_date'].dt.year\n",
    "df['invoice_month'] = df['invoice_date'].dt.strftime('%B')\n",
    "df['total_revenue'] = df['quantity'] * df['price']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbd474",
   "metadata": {},
   "source": [
    "<!-- What was the total sales revenue for the last quarter?\n",
    "How does the sales revenue of this year compare to the same period last year?\n",
    "What is the average transaction value for online purchases versus in-store purchases?\n",
    "Which month had the highest sales revenue in the last year?\n",
    "How has the sales revenue changed over the past six months?\n",
    "Is there a specific day of the week that consistently generates the highest sales?\n",
    "What is the total revenue generated by each payment method?\n",
    "What is the correlation between invoice quantity and total sales revenue?\n",
    "How does sales revenue vary among different shopping malls?\n",
    "Can you identify any trends or patterns in the distribution of sales revenue? -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def format_revenue_with_thousand_separator(x):\n",
    "    \"\"\"\n",
    "        function to format the revenue values with thousand separators\n",
    "    \"\"\"\n",
    "    return \"${:,.2f}\".format(x)\n",
    "\n",
    "class ExploreData():\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        \n",
    "        self.data = data\n",
    "    \n",
    "    def percentage_missing(self):\n",
    "        \n",
    "        \"\"\"Get summary of missing values in the data\n",
    "        \"\"\"\n",
    "        missing = pd.DataFrame(self.data.isnull().sum().reset_index().values, columns=['variable','missing'])\n",
    "        missing['%_missing'] = missing['missing']/len(self.data) * 100\n",
    "        d_types = pd.DataFrame(self.data.dtypes).reset_index()\n",
    "        d_types.columns = ['variable', 'dtype']\n",
    "        missing = missing.merge(d_types, on='variable')\n",
    "\n",
    "        return missing\n",
    "\n",
    "\n",
    "    def check_skewness(self, variable):\n",
    "        \n",
    "        \"\"\"Check skewness of a variables\n",
    "        \"\"\"\n",
    "\n",
    "        # calculate skewness\n",
    "        print(\"Skewness coefficient: \", self.data[variable].skew())\n",
    "\n",
    "        # Plot histogram\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.hist(self.data[variable], bins='auto', alpha=0.7, rwidth=0.85)\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.xlabel('Value',color='blue',fontsize=11)\n",
    "        plt.ylabel('Frequency',color='blue',fontsize=11)\n",
    "        plt.title(f'Distribution of {variable}', fontdict={\"size\":12, \"color\":\"blue\"})\n",
    "        \n",
    "        # add thousand separator to y-axis labels\n",
    "        plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('{x:,.0f}'))\n",
    "        plt.gca().xaxis.set_major_formatter(mticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.grid(True)\n",
    "        plt.tick_params(axis='x', which='both', labelsize=9, labelcolor='blue')\n",
    "        plt.tick_params(axis='y', which='both', labelsize=9, labelcolor='blue')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def get_statistical_summary(self, variableType=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Get statistical summary of numerical varaibles the dataframe\"\"\"\n",
    "                   \n",
    "        # missing values and data types\n",
    "        d_types = pd.DataFrame(self.data.dtypes).reset_index()\n",
    "        d_types.columns = ['variable', 'dtype']\n",
    "        \n",
    "        missing = pd.DataFrame(self.data.isnull().sum().reset_index().values, columns=['variable','missing'])\n",
    "        missing['%_missing'] = missing['missing']/len(self.data) * 100\n",
    "        d_types_df = pd.DataFrame(self.data.dtypes).reset_index()\n",
    "        d_types_df.columns = ['variable', 'dtype']\n",
    "        \n",
    "        # mapping of data types to human-readable text\n",
    "        data_type_mapping = {\n",
    "                                np.dtype('O'): 'Text',\n",
    "                                np.dtype('int64'): 'Integer',\n",
    "                                np.dtype('float64'): 'Float',\n",
    "                                np.dtype('<M8[ns]'): 'Date/Time'\n",
    "                            }\n",
    "        # Convert 'dtype' values to human-readable text\n",
    "        d_types_df['dtype'] = d_types_df['dtype'].map(data_type_mapping)\n",
    "        \n",
    "        missing = d_types_df.merge(missing, on='variable')\n",
    "     \n",
    "        # descriptive statistics\n",
    "        summary_statistics = self.data.describe(include=\"all\").T.reset_index().rename(columns={'index':'variable'})\n",
    "\n",
    "        # calculate unique values in each column\n",
    "        unique_values = {col: self.data[col].nunique() for col in summary_statistics['variable'].unique()}\n",
    "        unique_df = pd.DataFrame.from_dict(unique_values, orient='index', \n",
    "                        columns=['num_unique']).reset_index().rename(columns={'index':\"variable\"})\n",
    "        \n",
    "        # median\n",
    "        median_values = {col: self.data[col].median() for col in summary_statistics['variable'].unique() \n",
    "                         if self.data[col].dtype!='object'}\n",
    "        median_df = pd.DataFrame.from_dict(median_values, orient='index', \n",
    "                        columns=['median']).reset_index().rename(columns={'index':\"variable\"})\n",
    "\n",
    "        # mode\n",
    "        modal_values = {}\n",
    "        for col in summary_statistics['variable'].unique():\n",
    "            modes = self.data[col].mode()\n",
    "            if not modes.empty:\n",
    "                modal_values[col] = modes.iat[0]\n",
    "            else:\n",
    "                modal_values[col] = None\n",
    "                \n",
    "        modal_df = pd.DataFrame.from_dict(modal_values, orient='index', \n",
    "                        columns=['mode']).reset_index().rename(columns={'index': 'variable'})\n",
    "\n",
    "        # skewness\n",
    "        skewness_values = {col: self.data[col].skew() for col in summary_statistics['variable'].unique() \n",
    "                           if self.data[col].dtype not in ['object','datetime64[ns]']}\n",
    "        skewness_df = pd.DataFrame.from_dict(skewness_values, orient='index', \n",
    "                        columns=['skewness']).reset_index().rename(columns={'index':\"variable\"})\n",
    "\n",
    "        # number of outliers\n",
    "        outliers_df = pd.DataFrame(columns=[\"variable\",\"num_outliers\"])\n",
    "        cols = summary_statistics['variable'].unique()\n",
    "        for col in cols:\n",
    "            if self.data[col].dtype in ['object','datetime64[ns]']:\n",
    "                num_outliers=None\n",
    "            else:\n",
    "                z_scores = zscore(df[col])\n",
    "                num_outliers = (abs(z_scores) > 3).sum()\n",
    "                \n",
    "            outliers_df = outliers_df.append({'variable': col, 'num_outliers': num_outliers},ignore_index=True)\n",
    "       \n",
    "        # check for normality using Shapiro wilk test\n",
    "        normality_df = pd.DataFrame(columns=[\"variable\",\"statistic\",\"pValue\"])\n",
    "        for col in self.data.columns:\n",
    "            if self.data[col].dtype not in ['object','datetime64[ns]']:\n",
    "            \n",
    "                stat, p = stats.shapiro(self.data[col])\n",
    "                normality_df = normality_df.append({\"variable\":col,\"statistic\":stat,\"pValue\":p}, ignore_index=True)\n",
    "                \n",
    "        # if p_value > 0.05, then the distribution is normal\n",
    "        normality_df['normality'] = np.where(normality_df['pValue']>0.05,True,False)\n",
    "        normality_df.drop(columns=['statistic','pValue'], inplace=True)\n",
    "    \n",
    "        # summary\n",
    "        summary_statistics = missing.merge(summary_statistics, on='variable')\n",
    "        summary_statistics = summary_statistics.merge(unique_df, on='variable')\n",
    "        summary_statistics = summary_statistics.merge(median_df, on='variable',how='left')\n",
    "        summary_statistics = summary_statistics.merge(modal_df, on='variable',how='left')\n",
    "        summary_statistics = summary_statistics.merge(skewness_df, on='variable', how='left')\n",
    "        summary_statistics = summary_statistics.merge(outliers_df, on='variable',how='left')\n",
    "        summary_statistics = summary_statistics.merge(normality_df, on='variable',how='left')\n",
    "        \n",
    "        summary_statistics.drop(columns=['unique','top','freq'],inplace=True)\n",
    "    \n",
    "        if variableType=='numerical':\n",
    "            result = summary_statistics[summary_statistics['dtype'].isin(['Integer','Float'])]\n",
    "            result.dropna(axis=1, inplace=True)\n",
    "            \n",
    "        elif variableType=='categorical':\n",
    "            result = summary_statistics[summary_statistics['dtype'].isin(['Text','Date/Time'])]\n",
    "            columns_to_drop = ['mean','std','min','25%','50%','75%','max',\n",
    "                              'median','skewness','num_outliers','normality'] \n",
    "            result.drop(columns=columns_to_drop, inplace=True)\n",
    "            \n",
    "        else:\n",
    "            result = summary_statistics\n",
    "        \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the proportion of missing values\n",
    "explore = ExploreData(df)\n",
    "explore.percentage_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13604a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "explore.check_skewness('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get statistical summary of categorical variables\n",
    "explore.get_statistical_summary(variableType='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443dca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get statistical summary of numerical variables\n",
    "explore.get_statistical_summary(variableType='numerical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b459c6",
   "metadata": {},
   "source": [
    "### 1. What was the total sales revenue for the last quarter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for last 3 months\n",
    "last_date = df['invoice_date'].max()\n",
    "three_months_ago = last_date - timedelta(days=90)\n",
    "last_quarter_data = df[(df['invoice_date'] >= three_months_ago) & (df['invoice_date'] <= last_date)]\n",
    "\n",
    "total_sales_revenue_last_quarter = round(last_quarter_data['total_revenue'].sum(),2)\n",
    "total_sales_revenue_last_quarter = format(total_sales_revenue_last_quarter,',.2f')\n",
    "\n",
    "print(\"Total sales revenue for the last quarter: ${}\".format(total_sales_revenue_last_quarter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b088e0",
   "metadata": {},
   "source": [
    "### 2. How does the sales revenue of this year compare to the same period last year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfcf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_sales_revenue(target_period):\n",
    "    \n",
    "    if not isinstance(target_period, int):\n",
    "        print(\"Target period not valid\")\n",
    "        \n",
    "    elif (target_period < 1) | (target_period > 12):\n",
    "        print(\"Target period not valid\")\n",
    " \n",
    "    else:\n",
    "        \n",
    "        data = df.copy()\n",
    "\n",
    "        # Convert 'invoice_month' to datetime format to extract the month number\n",
    "        data['invoice_month'] = pd.to_datetime(data['invoice_month'], format='%B').dt.month\n",
    "\n",
    "        this_year = datetime.now().year\n",
    "        this_year_data = data[(data['invoice_year'] == this_year) & (data['invoice_month'] <= target_period)]\n",
    "\n",
    "        # Filter data for the same period last year\n",
    "        last_year = this_year - 1\n",
    "        last_year_data = data[(data['invoice_year'] == last_year) & (data['invoice_month'] <= target_period)]\n",
    "\n",
    "        # Calculate total sales revenue for this year and last year\n",
    "        total_sales_revenue_this_year = this_year_data['total_revenue'].sum()\n",
    "        total_sales_revenue_last_year = last_year_data['total_revenue'].sum()\n",
    "\n",
    "        # Calculate the sales revenue difference and percentage change\n",
    "        revenue_difference = total_sales_revenue_this_year - total_sales_revenue_last_year\n",
    "        percentage_change = (revenue_difference / total_sales_revenue_last_year) * 100\n",
    "\n",
    "        print(f\"Sales revenue this year: ${format(total_sales_revenue_this_year,',.2f')}\")\n",
    "        print(f\"Sales revenue last year: ${format(total_sales_revenue_last_year,',.2f')}\")\n",
    "\n",
    "        print(f\"Revenue difference: ${format(revenue_difference,',.2f')}\")\n",
    "        print(f\"Percentage change: {percentage_change:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52036b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_sales_revenue(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd95ce55",
   "metadata": {},
   "source": [
    "### 3. What is the average transaction value for card purchases versus cash purchases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aaddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average transaction value for debit and credit card purchases\n",
    "average_card_transaction = df[(df['payment_method'] == 'Credit Card') |\\\n",
    "                        (df['payment_method'] == 'Debit Card')]['total_revenue'].mean()\n",
    "\n",
    "# average transaction value for cash purchases\n",
    "average_cash_transaction = df[df['payment_method'] == 'Cash']['price'].mean()\n",
    "\n",
    "print(f\"Average card transaction value: ${average_card_transaction:,.2f}\")\n",
    "print(f\"Average cash transaction value: ${average_cash_transaction:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ea9d5",
   "metadata": {},
   "source": [
    "### 4. Which month had the highest sales revenue in the last year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc05189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales revenue for last year\n",
    "this_year = datetime.now().year\n",
    "last_year = this_year - 1\n",
    "last_year_data = df[df['invoice_year'] == last_year]\n",
    "monthly_sales_last_year = last_year_data.groupby('invoice_month')['total_revenue'].sum()\n",
    "\n",
    "# month with highest sales revenue\n",
    "month_with_highest_sales = monthly_sales_last_year.idxmax()\n",
    "sales_for_the_month = monthly_sales_last_year.max()\n",
    "\n",
    "print(f\"The month in the last year with the highest total sales: {month_with_highest_sales} - ${sales_for_the_month:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c8e8da",
   "metadata": {},
   "source": [
    "### 5. How has the sales revenue changed over the past six months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57864fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get date for last 3 months\n",
    "last_date = df['invoice_date'].max()\n",
    "six_months_ago = last_date - timedelta(days=180)\n",
    "\n",
    "# data for the last quarter\n",
    "last_half_data = df[(df['invoice_date'] >= six_months_ago) & (df['invoice_date'] <= last_date)]\n",
    "\n",
    "monthly_sales = last_half_data.groupby(last_half_data['invoice_date'].dt.to_period('M'))['total_revenue'].sum()\n",
    "monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c62693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sales revenue changes over the past six months\n",
    "plt.figure(figsize=(10, 5))\n",
    "monthly_sales.plot(kind='line', marker='o')\n",
    "\n",
    "plt.title(\"Sales Revenue Over the Past Six Months\", color='blue', fontsize=11)\n",
    "plt.xlabel(\"Month\",color='blue', fontsize=11)\n",
    "plt.ylabel(\"Total sales revenue\",color='blue', fontsize=11)\n",
    "\n",
    "# add thousand separator to y-axis labels\n",
    "plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('${x:,.0f}'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tick_params(axis='x', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.tick_params(axis='y', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f15292",
   "metadata": {},
   "source": [
    "### 6. Is there a specific day of the week that consistently generates the highest sales revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average sales revenue for each day of week\n",
    "df['day_of_week'] = df['invoice_date'].dt.day_name()\n",
    "daily_avg_sales = df.groupby('day_of_week')['total_revenue'].mean()\n",
    "\n",
    "# day of week with the highest average sales revenue\n",
    "day_with_highest_avg_sales = daily_avg_sales.idxmax()\n",
    "print(\"===========================================================\")\n",
    "print(f\"The day of the week with the highest average sales: {day_with_highest_avg_sales}\")\n",
    "\n",
    "# Plot the average sales for each day of the week\n",
    "plt.figure(figsize=(10, 5))\n",
    "daily_avg_sales.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Average Sales by Day of the Week\", color='blue',fontsize=12)\n",
    "plt.xlabel(\"Day of the Week\",color='blue',fontsize=12)\n",
    "plt.ylabel(\"Average Sales\",color='blue',fontsize=12)\n",
    "\n",
    "# add thousand separator to y-axis labels\n",
    "plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('${x:,.0f}'))\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "plt.tick_params(axis='x', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.tick_params(axis='y', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1316102d",
   "metadata": {},
   "source": [
    "### 7. What is the total revenue generated by each payment method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca08249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revenue for each payment method\n",
    "revenue_by_payment_method = df.groupby('payment_method')['total_revenue'].sum().reset_index()\n",
    "revenue_by_payment_method['total_revenue'] = \\\n",
    "            revenue_by_payment_method['total_revenue'].apply(format_revenue_with_thousand_separator)\n",
    "\n",
    "revenue_by_payment_method.rename(columns={'payment_method':'Payment Method',\n",
    "            'total_revenue':'Total Revenue'},inplace=True)\n",
    "\n",
    "revenue_by_payment_method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29741cd1",
   "metadata": {},
   "source": [
    "### 8. What is the correlation between invoice quantity and price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between invoice quantity and price\n",
    "correlation = df['quantity'].corr(df['price'])\n",
    "\n",
    "print(f\"Correlation between invoice quantity and price: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f1317",
   "metadata": {},
   "source": [
    "### 9. How does sales revenue vary among different shopping malls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e4c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sales revenue for each mall\n",
    "revenue_by_mall = df.groupby('shopping_mall')['total_revenue'].sum()\n",
    "revenue_by_mall = revenue_by_mall.sort_values(ascending=False)\n",
    "\n",
    "# Plot the sales revenue for each shopping mall\n",
    "plt.figure(figsize=(10, 5))\n",
    "revenue_by_mall.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Sales Revenue by Shopping Mall\", color='blue',fontsize=12)\n",
    "plt.xlabel(\"Shopping Mall\",color='blue',fontsize=12)\n",
    "plt.ylabel(\"Total Sales Revenue\",color='blue',fontsize=12)\n",
    "\n",
    "# add thousand separator to y-axis labels\n",
    "plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('${x:,.0f}'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tick_params(axis='x', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.tick_params(axis='y', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51efcc",
   "metadata": {},
   "source": [
    "### 10. Can you identify any trends or patterns in the distribution of sales revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ba17c",
   "metadata": {},
   "source": [
    "#### a. Sales trend by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b981af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sales revenue for each month\n",
    "monthly_revenue = df.groupby(df['invoice_date'].dt.to_period('M'))['total_revenue'].sum()\n",
    "\n",
    "# Plot the trend of sales revenue over time\n",
    "plt.figure(figsize=(10, 5))\n",
    "monthly_revenue.plot(kind='line', marker='o')\n",
    "plt.title(\"Trend of Sales Revenue Over Time\", color='blue', fontsize=12)\n",
    "plt.xlabel(\"Month\",color='blue', fontsize=12)\n",
    "plt.ylabel(\"Total Sales Revenue\",color='blue', fontsize=12)\n",
    "\n",
    "# add thousand separator to y-axis labels\n",
    "plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('${x:,.0f}'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tick_params(axis='x', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.tick_params(axis='y', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629dd043",
   "metadata": {},
   "source": [
    "#### b. Sales trend by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cfcb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sales revenue for each category\n",
    "category_monthly_revenue = df.groupby([df['invoice_date'].dt.to_period('M'),\n",
    "                'category'])['total_revenue'].sum().reset_index()\n",
    "\n",
    "# Pivot the data to create a matrix with months as rows, categories as columns, and sales revenue as values\n",
    "pivot_table = category_monthly_revenue.pivot(index='invoice_date', columns='category',\n",
    "                values='total_revenue')\n",
    "\n",
    "# Plot the trend of sales revenue for each product category over time\n",
    "pivot_table.plot(kind='line', marker='o', figsize=(12,6))\n",
    "plt.title(\"Trend of Sales Revenue by Product Category Over Time\",color='blue', fontsize=12)\n",
    "plt.xlabel(\"Month\",color='blue', fontsize=12)\n",
    "plt.ylabel(\"Total Sales Revenue\",color='blue', fontsize=12)\n",
    "\n",
    "# add thousand separator to y-axis labels\n",
    "plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('${x:,.0f}'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Category')\n",
    "plt.tick_params(axis='x', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.tick_params(axis='y', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200da03",
   "metadata": {},
   "source": [
    "#### c. Seasonality of sales revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sales revenue for each month\n",
    "monthly_revenue = df.groupby(df['invoice_date'].dt.to_period('M'))['total_revenue'].sum()\n",
    "\n",
    "# Convert PeriodIndex to regular DatetimeIndex\n",
    "monthly_revenue.index = monthly_revenue.index.to_timestamp()\n",
    "\n",
    "# Perform time series decomposition (seasonal, trend, and residual)\n",
    "decomposition = sm.tsa.seasonal_decompose(monthly_revenue, model='additive')\n",
    "\n",
    "# Plot the decomposed time series components\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(decomposition.observed, label='Observed')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(decomposition.trend, label='Trend')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(decomposition.seasonal, label='Seasonal')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(decomposition.resid, label='Residual')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30378c12",
   "metadata": {},
   "source": [
    "#### d. Sales trend by payment method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by product and month, and calculate total sales revenue for each combination\n",
    "product_monthly_revenue = df.groupby([df['invoice_date'].dt.to_period('M'), 'payment_method'])['total_revenue'].sum().reset_index()\n",
    "\n",
    "# Pivot the data to create a matrix with months as rows, products as columns, and sales revenue as values\n",
    "pivot_table = product_monthly_revenue.pivot(index='invoice_date', columns='payment_method', values='total_revenue')\n",
    "\n",
    "# Plot the trend of sales revenue for each product over time\n",
    "pivot_table.plot(kind='line', marker='o',figsize=(12, 6))\n",
    "plt.title(\"Trend of Sales Revenue for Pyament Method Over Time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Sales Revenue\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Payment Method')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdddda7",
   "metadata": {},
   "source": [
    "#### e. Product launch trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch date of each new product\n",
    "new_product_launches = df[df['category'].duplicated(keep='first') == False]\n",
    "\n",
    "# sales revenue for each new product in the months following its launch\n",
    "months_after_launch = 6  \n",
    "new_product_performance = []\n",
    "\n",
    "for index, row in new_product_launches.iterrows():\n",
    "    launch_date = row['invoice_date']\n",
    "    product_name = row['category']\n",
    "    end_date = launch_date + pd.DateOffset(months=months_after_launch)\n",
    "    product_sales = df[(df['category'] == product_name) & (df['invoice_date'] >= launch_date) & (df['invoice_date'] <= end_date)]['total_revenue'].sum()\n",
    "    new_product_performance.append({'category': product_name, 'Launch Date': launch_date, 'Sales Revenue': product_sales})\n",
    "\n",
    "# new product performance\n",
    "new_product_performance_df = pd.DataFrame(new_product_performance)\n",
    "\n",
    "# Plot the sales revenue trends for new products\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(new_product_performance_df['Launch Date'], new_product_performance_df['Sales Revenue'], color='skyblue')\n",
    "plt.title(\"Sales Revenue Trends for New Product Launches\")\n",
    "plt.xlabel(\"Launch Date\")\n",
    "plt.ylabel(\"Sales Revenue\")\n",
    "\n",
    "# add thousand separator to y-axis labels\n",
    "plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('${x:,.0f}'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tick_params(axis='x', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.tick_params(axis='y', which='both', labelsize=9, labelcolor='blue')\n",
    "plt.show()\n",
    "\n",
    "new_product_performance_df['Sales Revenue'] = new_product_performance_df['Sales Revenue'].apply(format_revenue_with_thousand_separator)\n",
    "new_product_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49f14c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
